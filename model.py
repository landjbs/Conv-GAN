"""
Implements base model class for deep convolutional adversarial network
"""

# def assert_types(obj, name, expectedType):
#     """ Helper to assert proper typing of function inputs """
#     assert isinstance(obj, expectedType), f'{name} expected type {expectedType}, but found type {type{obj}}'

from keras.layers import Input, Conv2D, Activation, LeakyReLU, Dropout, Flatten, Dense
from keras.models import Model

class GAN(object):

    def __init__(self, name, rowNum, columnNum, channelNum):
        self.name   =   name
        # data formats
        self.rowNum     =   rowNum
        self.columnNum  =   columnNum
        self.channelNum =   channelNum
        # model structures
        self.discriminatorStructure =   None
        self.generatorStructure     =   None
        # compiled models
        self.discriminatorCompiled  =   None
        self.generatorCompiled      =   None
        ## model building params ##
        # default first-layer filter depth of discriminator
        self.DIS_DEPTH          =   64
        # default dropout; should prevent memorization
        self.DROPOUT            =   0.4
        # default kernel size
        self.KERNEL_SIZE        =   5
        # default convolution stride length
        self.STRIDE             =   2
        # default alpha of LeakyReLU activation in discriminator
        self.LEAKY_ALPHA        =   0.2
        # dimensions of generator latent space
        self.LATENT_DIMS        =   100
        # default momentum for adjusting mean and var in generator batch norm
        self.NORM_MOMENTUM      =   0.9

    def dis_get_filter_num(self, LAYER_COUNTER):
        """
        Determines number of filters to use on convolution layer assuming layer
        count starts at 1.
        """
        return (self.DIS_DEPTH * (2 ** (LAYER_COUNTER - 1)))

    def gen_get_filter_num(self, LAYER_COUNTER):
        """
        Determines number of filters to use on transpose convolution layer
        assuming filters were generated by dis_get_filter_num() and layer count
        starts at 1.
        """
        return (self.GEN_DEPTH / (2 ** LAYER_COUNTER))

    class ModelWarning(Warning):
        """ Class for warnings related to model building and compiling """
        pass

    def build_discriminator(self):
        """
        Builds discriminator architecture without compiling model
        """
        if self.discriminatorStructure:
            raise ModelWarning('Discriminator has already been built.')
            return self.discriminatorStructure
        # set up local vars for building
        INPUT_SHAPE     =   (self.rowNum, self.columnNum, self.channelNum)
        KERNEL_SIZE     =   self.KERNEL_SIZE
        STRIDE          =   self.STRIDE
        DROPOUT         =   self.DROPOUT
        LEAKY_ALPHA     =   self.LEAKY_ALPHA
        LAYER_COUNTER   =   1
        ## discriminator architecture ##
        inputs = Input(shape=INPUT_SHAPE, name='inputs')
        # first conv block
        conv_1 = Conv2D(filters=self.dis_get_filter_num(LAYER_COUNTER),
                        kernel_size=KERNEL_SIZE,
                        strides=STRIDE,
                        input_shape=INPUT_SHAPE,
                        padding='same',
                        name=f'conv_{LAYER_COUNTER}')(inputs)
        relu_1 = Activation(activation=LeakyReLU(RELU_ALPHA),
                            name=f'relu_{LAYER_COUNTER}')(conv_1)
        drop_1 = Dropout(rate=DROPOUT, name=f'drop_{LAYER_COUNTER}')(relu_1)
        # second conv block
        LAYER_COUNTER += 1
        conv_2 = Conv2D(filters=self.dis_get_filter_num(LAYER_COUNTER),
                        kernel_size=KERNEL_SIZE,
                        strides=STRIDE,
                        input_shape=INPUT_SHAPE,
                        padding='same',
                        name=f'conv_{LAYER_COUNTER}')(inputs)
        relu_2 = Activation(activation=LeakyReLU(RELU_ALPHA),
                            name=f'relu_{LAYER_COUNTER}')(conv_2)
        drop_2 = Dropout(rate=DROPOUT, name=f'drop_{LAYER_COUNTER}')(relu_2)
        # third conv block
        LAYER_COUNTER += 1
        conv_3 = Conv2D(filters=self.dis_get_filter_num(LAYER_COUNTER),
                        kernel_size=KERNEL_SIZE,
                        strides=STRIDE,
                        input_shape=INPUT_SHAPE,
                        padding='same',
                        name=f'conv_{LAYER_COUNTER}')(drop_2)
        relu_3 = Activation(activation=LeakyReLU(RELU_ALPHA),
                            name=f'relu_{LAYER_COUNTER}')(conv_3)
        drop_3 = Dropout(rate=DROPOUT, name=f'drop_{LAYER_COUNTER}')(relu_3)
        # fourth conv block
        LAYER_COUNTER += 1
        conv_4 = Conv2D(filters=self.dis_get_filter_num(LAYER_COUNTER),
                        kernel_size=KERNEL_SIZE,
                        strides=STRIDE,
                        input_shape=INPUT_SHAPE,
                        padding='same',
                        name=f'conv_{LAYER_COUNTER}')(drop_3)
        relu_4 = Activation(activation=LeakyReLU(RELU_ALPHA),
                            name=f'relu_{LAYER_COUNTER}')(conv_4)
        drop_4 = Dropout(rate=DROPOUT, name=f'drop_{LAYER_COUNTER}')(relu_4)
        # convolutional output is flattened and passed to dense classifier
        flat = Flatten(name='flat')(drop_4)
        outputs = Dense(units=1, activation='sigmoid', name='outputs')(flat)
        # build sequential model
        discriminatorStructure = Model(inputs=inputs, outputs=outputs)
        self.discriminatorStructure = discriminatorStructure
        return discriminatorStructure
