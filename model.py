"""
Implements base model class for deep convolutional adversarial network
"""

# def assert_types(obj, name, expectedType):
#     """ Helper to assert proper typing of function inputs """
#     assert isinstance(obj, expectedType), f'{name} expected type {expectedType}, but found type {type{obj}}'

from keras.layers import (Input, Conv2D, Activation, LeakyReLU, Dropout,
                            Flatten, Dense, BatchNormalization, ReLU,
                            UpSampling2D, Conv2DTranspose, Reshape)
from keras.models import Model

import keras

class GAN(object):

    def __init__(self, name, rowNum, columnNum, channelNum):
        self.name   =   name
        # data formats
        self.rowNum     =   rowNum
        self.columnNum  =   columnNum
        self.channelNum =   channelNum
        self.imageShape =   (rowNum, columnNum, channelNum)
        # model structures
        self.discriminatorStructure =   None
        self.generatorStructure     =   None
        # compiled models
        self.discriminatorCompiled  =   None
        self.generatorCompiled      =   None
        ## model building params ##
        # default first-layer filter depth of discriminator
        DIS_DEPTH               =   64
        self.DIS_DEPTH          =   DIS_DEPTH
        self.GEN_DEPTH          =   DIS_DEPTH * 4
        # default dropout; should prevent memorization
        self.DROPOUT            =   0.4
        # default kernel size
        self.KERNEL_SIZE        =   5
        # default convolution stride length
        self.STRIDE             =   2
        # default alpha of LeakyReLU activation in discriminator
        self.LEAKY_ALPHA        =   0.2
        # dimensions of generator latent space
        self.LATENT_DIMS        =   100
        # default momentum for adjusting mean and var in generator batch norm
        self.NORM_MOMENTUM      =   0.9

    def dis_get_filter_num(self, LAYER_COUNTER):
        """
        Determines number of filters to use on convolution layer assuming layer
        count starts at 1.
        """
        return (self.DIS_DEPTH * (2 ** (LAYER_COUNTER - 1)))

    def gen_get_filter_num(self, LAYER_COUNTER):
        """
        Determines number of filters to use on transpose convolution layer
        assuming filters were generated by dis_get_filter_num() and layer count
        starts at 1.
        """
        return int(self.GEN_DEPTH / (2 ** LAYER_COUNTER))

    class ModelWarning(Warning):
        # BUG: warning currently raises exception instead of warning
        """ Class for warnings related to model building and compiling """
        pass

    def build_discriminator(self):
        """
        Builds discriminator architecture without compiling model.
        Uses functional API to allow for easy insertion of non-sequential
        elements. If the model has already been build, it is simply returned.
        Input has the shape of a single image as specified during object
        initialization. Convolutional layers have a filter number determined
        by self.dis_get_filter_num(LAYER_COUNTER), use self.STRIDES strides
        for downsampling, and pad to match input shape. LeakyReLU functions
        with self.LEAKY_ALPHA alpha are used to give gradients to inactive
        units and self.DROPOUT dropout is used to prevent overfitting.
        Final output is the probability that the image is real, according to
        a single-node, dense layer with sigmoid activation.
        """
        if self.discriminatorStructure:
            raise self.ModelWarning('Discriminator has already been built.')
            return self.discriminatorStructure
        # set up local vars for building
        INPUT_SHAPE     =   self.imageShape
        KERNEL_SIZE     =   self.KERNEL_SIZE
        STRIDE          =   self.STRIDE
        DROPOUT         =   self.DROPOUT
        LEAKY_ALPHA     =   self.LEAKY_ALPHA
        LAYER_COUNTER   =   1
        ## discriminator architecture ##
        inputs = Input(shape=INPUT_SHAPE, name='inputs')
        # first conv block
        conv_1 = Conv2D(filters=self.dis_get_filter_num(LAYER_COUNTER),
                        kernel_size=KERNEL_SIZE,
                        strides=STRIDE,
                        input_shape=INPUT_SHAPE,
                        padding='same',
                        name=f'conv_{LAYER_COUNTER}')(inputs)
        relu_1 = LeakyReLU(RELU_ALPHA, name=f'relu_{LAYER_COUNTER}')(conv_1)
        drop_1 = Dropout(rate=DROPOUT, name=f'drop_{LAYER_COUNTER}')(relu_1)
        # second conv block
        LAYER_COUNTER += 1
        conv_2 = Conv2D(filters=self.dis_get_filter_num(LAYER_COUNTER),
                        kernel_size=KERNEL_SIZE,
                        strides=STRIDE,
                        input_shape=INPUT_SHAPE,
                        padding='same',
                        name=f'conv_{LAYER_COUNTER}')(drop_1)
        relu_2 = LeakyReLU(RELU_ALPHA, name=f'relu_{LAYER_COUNTER}')(conv_2)
        drop_2 = Dropout(rate=DROPOUT, name=f'drop_{LAYER_COUNTER}')(relu_2)
        # third conv block
        LAYER_COUNTER += 1
        conv_3 = Conv2D(filters=self.dis_get_filter_num(LAYER_COUNTER),
                        kernel_size=KERNEL_SIZE,
                        strides=STRIDE,
                        input_shape=INPUT_SHAPE,
                        padding='same',
                        name=f'conv_{LAYER_COUNTER}')(drop_2)
        relu_3 = LeakyReLU(RELU_ALPHA, name=f'relu_{LAYER_COUNTER}')(conv_3)
        drop_3 = Dropout(rate=DROPOUT, name=f'drop_{LAYER_COUNTER}')(relu_3)
        # fourth conv block
        LAYER_COUNTER += 1
        conv_4 = Conv2D(filters=self.dis_get_filter_num(LAYER_COUNTER),
                        kernel_size=KERNEL_SIZE,
                        strides=STRIDE,
                        input_shape=INPUT_SHAPE,
                        padding='same',
                        name=f'conv_{LAYER_COUNTER}')(drop_3)
        relu_4 = LeakyReLU(RELU_ALPHA, name=f'relu_{LAYER_COUNTER}')(conv_4)
        drop_4 = Dropout(rate=DROPOUT, name=f'drop_{LAYER_COUNTER}')(relu_4)
        # convolutional output is flattened and passed to dense classifier
        flat = Flatten(name='flat')(drop_4)
        outputs = Dense(units=1, activation='sigmoid', name='outputs')(flat)
        # build sequential model
        discriminatorStructure = Model(inputs=inputs, outputs=outputs)
        print(discriminatorStructure.summary())
        self.discriminatorStructure = discriminatorStructure
        return discriminatorStructure

    def build_generator(self):
        """ Builds generator architecture without compiling model """
        if self.generatorStructure:
            raise self.ModelWarning('Generator has already been built.')
            return self.generatorStructure
        # set up local vars for building
        LATENT_DIMS     =   self.LATENT_DIMS
        KERNEL_SIZE     =   self.KERNEL_SIZE
        DROPOUT         =   self.DROPOUT
        NORM_MOMENTUM   =   self.NORM_MOMENTUM
        GEN_DEPTH       =   self.GEN_DEPTH
        # # TEMP: Find out if better params exist
        GEN_DIM         =   7
        LATENT_RESHAPE  =   (GEN_DIM, GEN_DIM, GEN_DEPTH)
        LATENT_NODES    =   GEN_DIM * GEN_DIM * GEN_DEPTH
        LAYER_COUNTER   =   1
        ## generator architecture ##
        latent_inputs = Input(shape=(LATENT_DIMS, ), name='latent_inputs')
        # dense layer to adjust and norm latent space
        dense_latent = Dense(units=LATENT_NODES,
                            input_dim=GEN_INPUT_DIM,
                            name='dense_latent')(latent_inputs)
        batch_latent = BatchNormalization(momentum=NORM_MOMENTUM,
                                        name='batch_latent')(dense_latent)
        relu_latent = ReLU(name='relu_latent')(batch_latent)
        # reshape latent dims into image shape matrix
        reshaped_latent = Reshape(target_shape=LATENT_RESHAPE,
                                name='reshaped_latent')(relu_latent)
        dropout_latent = Dropout(rate=DROPOUT,
                                name='dropout_latent')(reshaped_latent)
        # first upsampling block
        upsample_1 = UpSampling2D(name=f'upsample_{LAYER_COUNTER}')(dropout_latent)
        transpose_1 = Conv2DTranspose(filters=self.gen_get_filter_num(LAYER_COUNTER),
                                    kernel_size=KERNEL_SIZE,
                                    padding='same',
                                    name=f'transpose_{LAYER_COUNTER}')(upsample_1)
        batch_1 = BatchNormalization(momentum=NORM_MOMENTUM,
                                    name=f'batch_{LAYER_COUNTER}')(transpose_1)
        relu_1 = ReLU(name=f'relu_{LAYER_COUNTER}')(batch_1)
        # second upsampling block
        LAYER_COUNTER += 1
        upsample_2 = UpSampling2D(name=f'upsample_{LAYER_COUNTER}')(relu_1)
        transpose_2 = Conv2DTranspose(filters=self.gen_get_filter_num(LAYER_COUNTER),
                                    kernel_size=KERNEL_SIZE,
                                    padding='same',
                                    name=f'transpose_{LAYER_COUNTER}')(upsample_2)
        batch_2 = BatchNormalization(momentum=NORM_MOMENTUM,
                                    name=f'batch_{LAYER_COUNTER}')(transpose_2)
        relu_2 = ReLU(name=f'relu_{LAYER_COUNTER}')(batch_2)
        # third upsampling block: no upsampling for now
        # QUESTION: Will transpose on final layers lead to artifacts?
        LAYER_COUNTER += 1
        transpose_3 = Conv2DTranspose(filters=self.gen_get_filter_num(LAYER_COUNTER),
                                    kernel_size=KERNEL_SIZE,
                                    padding='same',
                                    name=f'transpose_{LAYER_COUNTER}')(relu_2)
        batch_3 = BatchNormalization(momentum=NORM_MOMENTUM,
                                    name=f'batch_{LAYER_COUNTER}')(transpose_3)
        relu_3 = ReLU(name=f'relu_{LAYER_COUNTER}')(batch_3)
        # sigmoid activation on final output to assert grayscale output
        # in range [0, 1]
        output_transpose = Conv2DTranspose(filters=1,
                                            kernel_size=5,
                                            padding='same',
                                            name='output_transpose')(relu_3)
        outputs = Activation(activation='sigmoid')(output_transpose)
        # build sequential model
        generatorStructure = Model(inputs=latent_inputs, outputs=outputs)
        print(generatorStructure.summary())
        self.generatorStructure = generatorStructure
        return generatorStructure

    def compile_discriminator(self):
        """ Compiles discriminator model """
        if self.discriminatorCompiled:
            raise self.ModelWarning("Discriminator has already been compiled.")
            return discriminatorCompiled
        
